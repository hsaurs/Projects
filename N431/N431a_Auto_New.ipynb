{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "N431a_Auto_New.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10OXb-oNKVzO"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 3 / Assignment 1*\n",
        "# Convolutional Neural Networks (CNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lfZdD_cp1t5"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "케라스를 이용한 바이너리 이미지 분류 모델에 3가지 CNN 모델을 적용하여 보는 과제입니다. <br/>\n",
        "\n",
        "- [데이터 다운로드](https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/datasets/mountainForest.zip)\n",
        "\n",
        "산의 이미지(./data/mountin/*)와 숲의 이미지(./data/forest/*)를 분류하는 문제입니다. <br/>\n",
        "산을 Positive (1)로, 숲 이미지를 Negative(0)로 레이블링 하여줍니다.\n",
        "\n",
        "클래스당 약 350개의 이미지로 이루어져 있는데요.<br/>\n",
        "표본이 작다는 점을 감안하면 현실적으로 어려운 문제입니다.\n",
        "\n",
        "하지만 이번 과제에서는 해당 데이터에 여러 가지 모델을 적용해보는는 것에 중점을 두어 봅시다. <br/>\n",
        "과제를 통해 이미지 분류에 적용할 수 있는 여러 모델을 알아보고 서로를 비교하는 데 익숙해져 보면 좋겠죠?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-Ng0p_35yrh"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI3qR2nVKVzT"
      },
      "source": [
        "## Part 1 : Pre-trained Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXXsDSZvriLL"
      },
      "source": [
        "Keras에서 제공하는 pre-trained 모델인 ResNet50을 불러와서 사용해봅니다. [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1)은 50 개의 layer를 가진  CNN기반의 모델입니다. <br/>\n",
        "이미지를 [1000 개의 클래스로](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt)를 분류하는 모델인데요. 우리가 풀어야 할 과제는 2가지 이므로 마지막 출력단을 변경해서 사용해 볼 수 있습니다.\n",
        "\n",
        "\n",
        "`ResNet50`을 불러올 때, **`include_top=False`** 로 하면, 기존 1000가지 클래스로의 분류 문제를 풀 수 있는 ResNet 모델에서 Fully Connected layer 부분을 제거해주는 역할을 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQEk60uPkDvj",
        "outputId": "72a3e7ee-b295-4f5c-b11e-dcb6dbdb63c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "resnet = ResNet50(weights='imagenet', include_top=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_Km6oGLqP0z"
      },
      "source": [
        "아래 부분은 ResNet50 레이어들의 파라미터를 학습하지 않도록 설정합니다. <br/>\n",
        "이렇게 설정된 매개 변수는 역전파를 통해 오차 정보가 전파 되더라도 파라미터가 업데이트 되지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WekujLySkQRI"
      },
      "source": [
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qg5wDPPqV0P"
      },
      "source": [
        "모델에 추가로 **`Fully-conneted layer(Dense)`** 를 추가해야 합니다. <br/>\n",
        "사전 학습 모델을 불러오면서 최상위 레이어인 **`Fully-conneted layer`** 를 제거했기 때문이지요.\n",
        "\n",
        "새로 추가하는 **`Fully-conneted layer`** 에서는 목적인 이진 분류에 맞게 출력층을 설계하여 주어야 합니다. <br/> **`GlobalAveragePooling2D`** 레이어는 마지막 컨벌루션 레이어 출력(2 차원) 각각의 평균을 취해주어 **`Dense`** 층에 들어갈 수 있도록 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U36jk4_JkWNd"
      },
      "source": [
        "x = resnet.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x) # 출력층을 설계합니다.\n",
        "model = Model(resnet.input, predictions)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvJd3ItAKVzU"
      },
      "source": [
        "### Load in Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTcetvpqwO5X"
      },
      "source": [
        "[Keras ImageDataGenerator](https://keras.io/api/preprocessing/image/) 를 참고하여 데이터를 불러옵니다. <br/>\n",
        "위 링크뿐만 아니라 구글링을 통해 ImageDataGenerator 라이브러리에 대한 여러 예제를 조사하고 참고해보세요. \n",
        "\n",
        "Notebook을 여러분의 Google Drive에 Mount 한 후에 이미지를 불러오도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITE_Tw5wknZm",
        "outputId": "8b97864d-15ba-49c0-a33b-060ebffc9dbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYRS_BKGwWax"
      },
      "source": [
        "directory = \"/content/drive/My Drive/Colab Notebooks/mountainForest/train\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB6dGgeYwZij",
        "outputId": "59855764-8264-4bc4-8be8-173eb5ac7621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    image_size=(32, 32),\n",
        "    seed=42,\n",
        "    interpolation=\"bilinear\",\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 533 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oAmeNnZ3Iwy",
        "outputId": "1a18ba25-6d1b-4ab1-d2cd-4b2f71805107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 32, 32, 3), (None,)), types: (tf.float32, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3wOqyks2VU",
        "outputId": "5a4ddf4e-679c-4759-d918-9f01bb599be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train.class_names"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['forest', 'mountain']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Al2UJMGzEW_"
      },
      "source": [
        "directory = \"/content/drive/My Drive/Colab Notebooks/mountainForest/validation\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hekanDevp45L",
        "outputId": "cb109fcf-1a23-4797-a08c-9d8be8eaf358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    image_size=(32, 32),\n",
        "    seed=42,\n",
        "    interpolation=\"bilinear\",\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 195 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzezBMBKVza"
      },
      "source": [
        "### Instatiate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioC2kKT11A-h"
      },
      "source": [
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.models import Sequential, Model \n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC7ekieRybGE"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "\n",
        "# 클래스의 개수 정의 : Cats & Dogs \n",
        "NUM_CLASSES = 2\n",
        "\n",
        "# 입력 이미지의 차원 수 : RGB\n",
        "CHANNELS = 3\n",
        "# 학습된 네트워크 특징\n",
        "IMAGE_RESIZE = 224\n",
        "RESNET50_POOLING_AVERAGE = 'avg'\n",
        "DENSE_LAYER_ACTIVATION = 'softmax'\n",
        "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
        "\n",
        "# 출력 Metric\n",
        "LOSS_METRICS = ['accuracy']\n",
        "\n",
        "# EARLY_STOP_PATIENCE < NUM_EPOCHS\n",
        "NUM_EPOCHS = 10\n",
        "EARLY_STOP_PATIENCE = 3\n",
        "\n",
        "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
        "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
        "STEPS_PER_EPOCH_TRAINING = 10\n",
        "STEPS_PER_EPOCH_VALIDATION = 10\n",
        "\n",
        "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
        "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
        "BATCH_SIZE_TRAINING = 100\n",
        "BATCH_SIZE_VALIDATION = 100\n",
        "\n",
        "# 테스트 배치의 개수\n",
        "BATCH_SIZE_TESTING = 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0i14sSCKVzb"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE)) \n",
        "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
        "\n",
        "# 이미 학습된 영역은 학습하지 않겠다고 설정하는 옵션 \n",
        "model.layers[0].trainable = False"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtQX3ALdKVzf"
      },
      "source": [
        "### Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAfzvyqZ1E_Q"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPEt-wwuKVzg",
        "outputId": "2bdd6a1b-83b6-4ade-b733-4b407b45dd13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train,validation_data=test, epochs=10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 2s 61ms/step - loss: 0.2514 - accuracy: 0.8987 - val_loss: 0.5104 - val_accuracy: 0.8718\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 2s 60ms/step - loss: 0.2267 - accuracy: 0.9156 - val_loss: 0.4579 - val_accuracy: 0.8974\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 2s 60ms/step - loss: 0.1984 - accuracy: 0.9212 - val_loss: 0.4239 - val_accuracy: 0.8974\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 2s 58ms/step - loss: 0.2146 - accuracy: 0.9156 - val_loss: 0.4556 - val_accuracy: 0.9026\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 2s 61ms/step - loss: 0.1720 - accuracy: 0.9306 - val_loss: 0.4448 - val_accuracy: 0.8718\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 2s 58ms/step - loss: 0.1909 - accuracy: 0.9250 - val_loss: 0.4163 - val_accuracy: 0.8872\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 2s 57ms/step - loss: 0.2448 - accuracy: 0.9174 - val_loss: 0.5390 - val_accuracy: 0.8564\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 2s 61ms/step - loss: 0.2329 - accuracy: 0.9250 - val_loss: 0.4929 - val_accuracy: 0.8769\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 2s 58ms/step - loss: 0.1748 - accuracy: 0.9400 - val_loss: 0.4590 - val_accuracy: 0.8667\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 2s 59ms/step - loss: 0.1808 - accuracy: 0.9268 - val_loss: 0.4881 - val_accuracy: 0.8615\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fda11569d50>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjBDRtCw55Sb"
      },
      "source": [
        "## Part 2 : Custom CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gpEjsFpKVzj"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "이 단계에서는 Keras를 사용하여 자신 만의 CNN을 작성하고 훈련합니다. <br/>\n",
        "네트워크에 적어도 하나의 Conv 레이어와 pooling 레이어가있는 아키텍처를 만들어 사용해 보세요. <br/> 아래는 여러분이 참고할 수 있도록 표시한 결과이며 여러분의 마음대로 설계하여도 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St--__KE0mN5"
      },
      "source": [
        "### Make a Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgwLFkhUKVzj",
        "outputId": "2319b7d0-eb6f-4cc7-faa2-a2b6b101063f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "\n",
        "model= Sequential()\n",
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 72,898\n",
            "Trainable params: 72,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS18U9mP0f2F"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5NrX3K9KVzm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqy74Fpo0jXi"
      },
      "source": [
        "### Fit Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yju2nvVNKVzp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}